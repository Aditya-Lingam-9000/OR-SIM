# OR-SIM: Operating Room Simulator â€” Implementation Plan

> **Project Vision**: A real-time intelligent operating room simulator where a doctor's spoken commands
> (captured via microphone) are transcribed by MedASR, reasoned about by MedGemma, and used to
> dynamically control a 3D OR visualization â€” turning machines on/off, adjusting lighting, and
> animating surgical staff â€” all within a fraction of a second.

---

## Architecture Overview

```
[Microphone]
     â”‚
     â–¼
[MedASR ONNX â€” int8]          â† models/medasr/model.int8.onnx
     â”‚  live transcription
     â–¼
[MedGemma 4B Q3_K_M]          â† models/medgemma/medgemma-4b-it-Q3_K_M.gguf
     â”‚  system_prompt(surgery) + transcription + machines_dict
     â–¼
[output/machine_states.json]   â† continuously updated JSON {0: [...off], 1: [...on]}
     â”‚
     â–¼
[FastAPI WebSocket Server]
     â”‚
     â–¼
[Frontend â€” 3D OR Room Viz]    â† Three.js / Canvas, surgery-specific environment
     â””â”€ machines toggle on/off, lights, animated doctors respond live
```

---

## Surgery Types & Machine Dictionaries (Phase 2)

### 1. Heart Transplantation
- Patient Monitor, Ventilator, Cardiopulmonary Bypass Machine, Defibrillator,
  Electrocautery Unit, Suction Device, Warming Blanket, Anesthesia Machine,
  Perfusion Pump, Surgical Lights, Instrument Table, Blood Warmer

### 2. Liver Resection
- Patient Monitor, Ventilator, Anesthesia Machine, Electrocautery Unit,
  Argon Beam Coagulator, Suction Device, Ultrasonic Dissector (CUSA),
  Surgical Lights, Cell Saver, Fluid Warmer, Laparoscopy Tower, CO2 Insufflator

### 3. Kidney PCNL (Percutaneous Nephrolithotomy)
- Patient Monitor, Fluoroscopy C-Arm, Nephroscope Unit, Lithotripsy Device,
  Irrigation Pump, Suction Device, Anesthesia Machine, Surgical Lights,
  Electrocautery Unit, Contrast Injector, Video Tower, Stone Retrieval System

---

## JSON Machine State Format

```json
{
  "surgery": "Heart Transplantation",
  "timestamp": "2026-02-23T10:45:00.123Z",
  "transcription": "Turn on the cardiopulmonary bypass machine",
  "reasoning": "Doctor instructed activation of bypass machine during surgery",
  "machine_states": {
    "0": ["Ventilator", "Surgical Lights"],
    "1": ["Patient Monitor", "Anesthesia Machine", "Cardiopulmonary Bypass Machine"]
  }
}
```
- Key `"0"` â†’ machines currently **OFF**
- Key `"1"` â†’ machines currently **ON**
- This file is **overwritten on every update** â†’ frontend polls / WebSocket pushes delta

---

## Development Phases

---

### PHASE 0 â€” Project Foundation
**Goal**: Clean, reproducible dev environment with version control.

#### Sub-phases:
- [x] 0.1 Create virtual environment (`venv`)
- [x] 0.2 Initialize Git repo locally
- [x] 0.3 Create GitHub repository & push initial commit
- [x] 0.4 Create `.gitignore` (models, venv, __pycache__, output runtime files)
- [x] 0.5 Create base `requirements.txt`
- [x] 0.6 Create project folder skeleton

#### Folder Structure:
```
OR-SIM/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ IMPLEMENTATION_PLAN.md
â”œâ”€â”€ requirements/
â”‚   â”œâ”€â”€ base.txt          â† common deps
â”‚   â”œâ”€â”€ asr.txt           â† MedASR specific
â”‚   â”œâ”€â”€ llm.txt           â† MedGemma / llama-cpp specific
â”‚   â””â”€â”€ dev.txt           â† testing, linting
â”œâ”€â”€ models/               â† GITIGNORED (large files)
â”‚   â”œâ”€â”€ medasr/
â”‚   â””â”€â”€ medgemma/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ asr/              â† Phase 1
â”‚   â”œâ”€â”€ data/             â† Phase 2
â”‚   â”œâ”€â”€ llm/              â† Phase 3â€“4
â”‚   â”œâ”€â”€ pipeline/         â† Phase 5
â”‚   â””â”€â”€ server/           â† Phase 6
â”œâ”€â”€ output/               â† runtime JSON (gitignored during dev)
â”œâ”€â”€ logs/
â”œâ”€â”€ kaggle/               â† Kaggle notebooks for MedGemma testing
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ phase1/
â”‚   â”œâ”€â”€ phase2/
â”‚   â””â”€â”€ phase3/
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ phase_summaries/  â† one .md per completed phase
â””â”€â”€ frontend/             â† Phase 7 (last)
```

#### Sanity Check:
```bash
python --version          # should be 3.10+
git status                # clean working tree
pip list                  # confirm base packages installed
```

#### Git Tag: `v0.0-foundation`

---

### PHASE 1 â€” MedASR Real-Time Transcription
**Goal**: Speak into mic â†’ see accurate text on console within ~1 second.

#### Sub-phases:
- [ ] 1.1 Install and validate ONNX Runtime + audio deps
- [ ] 1.2 Load `model.int8.onnx` + `tokens.txt` â†’ verify model loads
- [ ] 1.3 Implement audio capture loop (`sounddevice`, 16kHz, mono, float32)
- [ ] 1.4 Implement chunked inference: sliding window (e.g. 1s chunks, 0.25s stride)
- [ ] 1.5 Implement greedy/beam decode â†’ text using `tokens.txt`
- [ ] 1.6 Accumulate and print live transcription with timestamps
- [ ] 1.7 Write unit test: feed recorded .wav â†’ compare expected text

#### Key Files:
```
backend/asr/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ model.py          â† load ONNX model, tokenizer
â”œâ”€â”€ audio.py          â† microphone capture, chunking
â”œâ”€â”€ transcriber.py    â† inference loop, decode, callback
â””â”€â”€ utils.py          â† audio preprocessing (resample, normalize)
tests/phase1/
â””â”€â”€ test_asr.py
```

#### Expected Output (console):
```
[00:00.000] Turn on the patient monitor
[00:02.450] Now activate the ventilator
[00:04.100] Turn on the anesthesia machine
```

#### Sanity / Manual Test:
1. Run `python -m backend.asr.transcriber`
2. Speak 5 surgery commands into mic
3. Verify text appears within â‰¤ 1.5 seconds of speaking
4. Confirm no crashes over 60 seconds of continuous audio

#### Git Tag: `v1.0-asr-live`

---

### PHASE 2 â€” Surgery & Machines Data Layer
**Goal**: A clean, importable data module with all 3 surgeries and their machine dictionaries.

#### Sub-phases:
- [ ] 2.1 Define `SurgeryType` enum (`HEART_TRANSPLANT`, `LIVER_RESECTION`, `KIDNEY_PCNL`)
- [ ] 2.2 Build machines dictionary for Heart Transplantation
- [ ] 2.3 Build machines dictionary for Liver Resection
- [ ] 2.4 Build machines dictionary for Kidney PCNL
- [ ] 2.5 Define `MachineState` and `ORState` Pydantic models
- [ ] 2.6 Implement `StateManager` â€” tracks current on/off states, serializes to JSON
- [ ] 2.7 Implement `output/machine_states.json` writer with atomic file write
- [ ] 2.8 Unit tests for state transitions

#### Machine Dictionary Format:
```python
MACHINES = {
    SurgeryType.HEART_TRANSPLANT: {
        0: {"name": "Patient Monitor",     "description": "Monitors vitals: HR, BP, SpO2, ECG continuously"},
        1: {"name": "Ventilator",           "description": "Controls mechanical breathing via ETT"},
        2: {"name": "Anesthesia Machine",   "description": "Delivers inhalational anesthetics and O2"},
        ...
    }
}
```

#### Key Files:
```
backend/data/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ surgeries.py      â† MACHINES dict, SurgeryType enum
â”œâ”€â”€ models.py         â† Pydantic: MachineState, ORState
â””â”€â”€ state_manager.py  â† StateManager class
tests/phase2/
â””â”€â”€ test_data.py
```

#### Expected Output:
```bash
python -m backend.data.surgeries
# Prints all 3 surgeries with machine count
# Heart Transplantation: 12 machines
# Liver Resection: 12 machines
# Kidney PCNL: 12 machines

python -m backend.data.state_manager
# Simulates 3 state transitions â†’ writes output/machine_states.json
# Prints diff after each transition
```

#### Git Tag: `v2.0-data-layer`

---

### PHASE 3 â€” MedGemma System Prompt & I/O Design
**Goal**: Design + validate the exact prompts and I/O contract for MedGemma â€” ensuring reliable JSON output.

#### Sub-phases:
- [ ] 3.1 Design system prompt template (surgery name + machines dict injected)
- [ ] 3.2 Design user message format (latest transcription chunk)
- [ ] 3.3 Define exact JSON output schema MedGemma must follow
- [ ] 3.4 Implement prompt builder (`PromptBuilder` class)
- [ ] 3.5 Implement JSON output parser + validator with fallback/retry logic
- [ ] 3.6 Create Kaggle notebook skeleton (`kaggle/phase3_medgemma_test.ipynb`)
- [ ] 3.7 **[KAGGLE TEST]** â€” Clone repo, run notebook, validate JSON output manually

#### System Prompt Template:
```
You are an intelligent operating room assistant for a {surgery_name} procedure.

AVAILABLE MACHINES:
{machines_dict_formatted}

Your role: Based on the surgeon's spoken instruction, determine which machines should be ON and which should be OFF.

ALWAYS respond ONLY in this exact JSON format:
{
  "reasoning": "<1 sentence explaining your decision>",
  "machine_states": {
    "0": ["<machine names to turn OFF>"],
    "1": ["<machine names to turn ON>"]
  }
}

Rules:
- Only include machines that CHANGE state in this turn
- Machine names must match exactly from the AVAILABLE MACHINES list
- Do not add any text outside the JSON block
```

#### Key Files:
```
backend/llm/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ prompt_builder.py    â† builds system + user prompts
â”œâ”€â”€ medgemma.py          â† loads GGUF, runs inference (llama-cpp-python)
â”œâ”€â”€ output_parser.py     â† extracts + validates JSON from LLM response
â””â”€â”€ schemas.py           â† Pydantic schema for LLM output
kaggle/
â””â”€â”€ phase3_medgemma_test.ipynb
```

#### Kaggle Test Protocol:
1. Push Phase 3 code to GitHub
2. On Kaggle (T4x2/P100): `git clone <repo>`
3. Install deps: `pip install -r requirements/llm.txt`
4. Run notebook with 10 sample transcriptions per surgery
5. Verify JSON output is valid, machine names match dict, reasoning is sensible
6. Measure inference time per call (target: < 3 seconds on T4)

#### Git Tag: `v3.0-llm-prompt-design`

---

### PHASE 4 â€” End-to-End Pipeline (ASR â†’ MedGemma â†’ JSON)
**Goal**: Speak a command â†’ JSON file updated with correct machine states within a few seconds.

#### Sub-phases:
- [ ] 4.1 Implement `PipelineOrchestrator` connecting ASR â†’ MedGemma â†’ StateManager
- [ ] 4.2 Implement async queue between ASR and LLM (avoid blocking audio capture)
- [ ] 4.3 Implement continuous `output/machine_states.json` overwrite loop
- [ ] 4.4 Implement latency measurement (ASR end â†’ JSON write timestamp)
- [ ] 4.5 Optimize: batch short utterances, skip silence, debounce
- [ ] 4.6 **[KAGGLE TEST]** â€” Full pipeline notebook with live microphone (or pre-recorded audio)
- [ ] 4.7 Validate: 10 commands, measure average end-to-end latency
- [ ] 4.8 Optimize GPU utilization (target: use both T4s via model parallelism or batching)

#### Key Files:
```
backend/pipeline/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ orchestrator.py   â† PipelineOrchestrator: ties ASR + LLM + StateManager
â”œâ”€â”€ queue.py          â† async queue for ASRâ†’LLM handoff
â””â”€â”€ latency.py        â† latency tracker / logger
kaggle/
â””â”€â”€ phase4_pipeline_test.ipynb
```

#### Expected Console Output:
```
[Pipeline] Surgery: Heart Transplantation
[ASR 00:01.2] "Turn on the patient monitor"
[LLM 00:02.8] States updated â†’ ON: [Patient Monitor]  (latency: 1.6s)
[ASR 00:04.0] "Activate the bypass machine"
[LLM 00:05.3] States updated â†’ ON: [Cardiopulmonary Bypass Machine]  (latency: 1.3s)
```

#### JSON output after 2 commands:
```json
{
  "surgery": "Heart Transplantation",
  "timestamp": "...",
  "machine_states": { "0": [...], "1": ["Patient Monitor", "Cardiopulmonary Bypass Machine"] }
}
```

#### Git Tag: `v4.0-pipeline-e2e`

---

### PHASE 5 â€” FastAPI Backend Server + WebSocket
**Goal**: Expose the pipeline over HTTP + WebSocket so the frontend can connect and receive live updates.

#### Sub-phases:
- [ ] 5.1 Create FastAPI app with lifespan â€” start pipeline on startup
- [ ] 5.2 `POST /api/session/start` â€” accepts `surgery_type`, initializes pipeline
- [ ] 5.3 `POST /api/session/stop` â€” gracefully shuts down pipeline
- [ ] 5.4 `GET /api/state` â€” returns current machine state JSON (REST polling fallback)
- [ ] 5.5 `WS /ws/state` â€” WebSocket that pushes state diffs on every JSON update
- [ ] 5.6 File watcher on `output/machine_states.json` â†’ triggers WebSocket broadcast
- [ ] 5.7 CORS setup for local frontend dev
- [ ] 5.8 Manual test: WebSocket client script + curl tests

#### Key Files:
```
backend/server/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ app.py          â† FastAPI app, lifespan, cors
â”œâ”€â”€ routes.py       â† REST endpoints
â”œâ”€â”€ websocket.py    â† WS manager, broadcaster
â””â”€â”€ watcher.py      â† watchdog file watcher â†’ triggers WS broadcast
```

#### Test with:
```bash
# Terminal 1
uvicorn backend.server.app:app --reload

# Terminal 2
python tests/phase5/ws_client_test.py  # connects to WS, prints received updates

# Terminal 3
python -m backend.asr.transcriber      # speak commands â†’ watch Terminal 2 update
```

#### Git Tag: `v5.0-backend-server`

---

### PHASE 6 â€” Frontend: OR Room Visualization
**Goal**: A browser-based 3D/2D surgical OR room that reacts live to machine state changes.

> **This phase begins ONLY after Phase 5 is fully validated end-to-end.**

#### Sub-phases:
- [ ] 6.1 Setup frontend scaffold (Vite + React + Three.js or PixiJS)
- [ ] 6.2 Surgery selection dropdown (3 types)
- [ ] 6.3 Per-surgery OR room scene with:
  - Surgical bed + patient model
  - All machines placed in anatomically correct positions
  - Overhead surgical lights
  - 2 animated doctor/nurse characters
- [ ] 6.4 WebSocket client integration â€” connect to `WS /ws/state`
- [ ] 6.5 Machine state renderer:
  - Machine ON â†’ glowing green indicator, active animation
  - Machine OFF â†’ dim gray, idle
- [ ] 6.6 Animated agent behavior:
  - On machine turn-on event â†’ doctor character walks to machine, activates it
  - On machine turn-off event â†’ doctor turns it off and returns
- [ ] 6.7 Light switching (surgical lights on/off)
- [ ] 6.8 Transcription live caption overlay at bottom of screen
- [ ] 6.9 Surgery-specific OR room assets (3 different room layouts)
- [ ] 6.10 Performance: smooth 60fps even during WS updates

#### Key Files:
```
frontend/
â”œâ”€â”€ index.html
â”œâ”€â”€ vite.config.js
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.jsx
â”‚   â”œâ”€â”€ App.jsx
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ SurgerySelector.jsx
â”‚   â”‚   â”œâ”€â”€ ORRoom.jsx            â† Three.js/PixiJS canvas
â”‚   â”‚   â”œâ”€â”€ MachineNode.jsx       â† individual machine component
â”‚   â”‚   â””â”€â”€ TranscriptionBar.jsx  â† live caption strip
â”‚   â”œâ”€â”€ scenes/
â”‚   â”‚   â”œâ”€â”€ HeartTransplantRoom.js
â”‚   â”‚   â”œâ”€â”€ LiverResectionRoom.js
â”‚   â”‚   â””â”€â”€ KidneyPCNLRoom.js
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ useORWebSocket.js      â† WS connection hook
â”‚   â””â”€â”€ store/
â”‚       â””â”€â”€ machineStore.js        â† Zustand state
â””â”€â”€ public/
    â””â”€â”€ assets/                    â† room models, textures
```

#### Git Tag: `v6.0-frontend-or-room`

---

## Phase Completion Checklist Template

After each phase, before moving to the next:

| Check | Status |
|-------|--------|
| All sub-phases marked done | â˜ |
| Unit tests pass | â˜ |
| Manual real-output test passed | â˜ |
| Phase summary doc written (`docs/phase_summaries/phaseN.md`) | â˜ |
| `.gitignore` reviewed and updated | â˜ |
| Git tag pushed | â˜ |
| Requirements files updated | â˜ |

---

## Kaggle Usage Protocol

MedGemma testing happens only on Kaggle (no local GPU):

1. Push latest code to GitHub
2. On Kaggle: `!git clone https://github.com/<you>/OR-SIM.git`
3. `!pip install -r OR-SIM/requirements/llm.txt`
4. Mount model: upload `.gguf` to Kaggle datasets OR copy from Kaggle's model hub
5. Run test notebook
6. Copy results (latency measurements, sample outputs) back to `docs/`
7. Commit findings

**GPU Strategy for Kaggle T4x2 (30GB total VRAM):**
- MedGemma 4B Q3_K_M â‰ˆ 2.1 GB â†’ fits easily on single T4
- MedASR int8 ONNX â‰ˆ 150 MB â†’ assign to CPU or second GPU
- Set `n_gpu_layers=-1` in llama-cpp to use all layers on GPU
- Use `n_threads=4` for CPU-side tokenization
- Enable `use_mlock=True` to prevent swapping

---

## Git Strategy

```
main         â† stable, phase-complete code
dev          â† active development
phase/N-xxx  â† feature branches per phase
```

```bash
# After each phase
git checkout main
git merge dev
git tag vN.0-phase-name
git push origin main --tags
```

---

## Requirements Summary

### requirements/base.txt
```
pydantic>=2.0
python-dotenv
loguru
watchdog
```

### requirements/asr.txt
```
onnxruntime>=1.17
sounddevice
numpy
scipy
```

### requirements/llm.txt
```
llama-cpp-python  (with CUDA)
```

### requirements/server.txt
```
fastapi
uvicorn[standard]
websockets
python-multipart
```

### requirements/dev.txt
```
pytest
pytest-asyncio
black
ruff
```

---

## Current Status

| Phase | Status | Git Tag |
|-------|--------|---------|
| Phase 0 â€” Foundation | ğŸ”„ In Progress | â€” |
| Phase 1 â€” MedASR | â³ Not Started | â€” |
| Phase 2 â€” Data Layer | â³ Not Started | â€” |
| Phase 3 â€” LLM Prompts (Kaggle) | â³ Not Started | â€” |
| Phase 4 â€” E2E Pipeline (Kaggle) | â³ Not Started | â€” |
| Phase 5 â€” Backend Server | â³ Not Started | â€” |
| Phase 6 â€” Frontend | â³ Not Started | â€” |

---

*This document will be updated at the completion of each phase.*
