{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "329feafd",
   "metadata": {},
   "source": [
    "# OR-SIM — End-to-End: Kaggle Backend + Local Frontend via ngrok\n",
    "\n",
    "**Goal:** Run the FastAPI/MedGemma/MedASR backend on a Kaggle GPU, expose it over the internet\n",
    "with ngrok, and connect the local React/Three.js frontend on your own machine.\n",
    "\n",
    "```\n",
    "Your Machine                       Kaggle Notebook (GPU)\n",
    "──────────────────────            ──────────────────────────────────────\n",
    "Browser → localhost:5173          │  uvicorn :8000  (FastAPI + MedGemma)\n",
    "   Vite dev-server                │      ↑\n",
    "        ↕  HTTPS / WSS            │  ngrok tunnel\n",
    "   ngrok public URL ──────────────┘\n",
    "```\n",
    "\n",
    "## Prerequisites\n",
    "| Requirement | Where to get it |\n",
    "|---|---|\n",
    "| Kaggle account with GPU quota | kaggle.com — enable T4 x2 in notebook settings |\n",
    "| ngrok account + auth token | dashboard.ngrok.com → *Your Authtoken* |\n",
    "| OR-SIM repo cloned locally | `d:\\OR-SIM` (already done) |\n",
    "| Kaggle dataset with the GGUF | Upload `medgemma-4b-it-Q3_K_M.gguf` as a private dataset |\n",
    "\n",
    "## Steps at a glance\n",
    "1. Run cells 1-8 in order on Kaggle\n",
    "2. Copy the **ngrok HTTPS URL** printed by cell 8\n",
    "3. On your local machine: create `frontend/.env.local`, paste the URL, `npm run dev`\n",
    "4. Open http://localhost:5173 – pick surgery – Start Session – speak!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4c0f3c",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 1 — Verify GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922bbb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys\n",
    "\n",
    "result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    # Print only the first 20 lines to keep output tidy\n",
    "    print('\\n'.join(result.stdout.splitlines()[:20]))\n",
    "else:\n",
    "    print('⚠  No GPU detected — go to Notebook Settings and enable a GPU accelerator.')\n",
    "    sys.exit('GPU required')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98769a9b",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 2 — Install llama-cpp-python (CUDA 12.4 prebuilt wheel)\n",
    "\n",
    "The Kaggle T4 instance ships CUDA 12.4. We install a prebuilt wheel instead of compiling\n",
    "from source (saves ~20 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cfc079",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Installing llama-cpp-python (CUDA 12.4 wheel)...')\n",
    "subprocess.run(\n",
    "    [\n",
    "        sys.executable, '-m', 'pip', 'install',\n",
    "        'llama-cpp-python==0.3.4',\n",
    "        '--extra-index-url', 'https://abetlen.github.io/llama-cpp-python/whl/cu124',\n",
    "        '--quiet',\n",
    "    ],\n",
    "    check=True,\n",
    ")\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de711af3",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 3 — Clone OR-SIM repo and install Python dependencies\n",
    "\n",
    "> **Update `REPO_URL`** to your own GitHub repository URL before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba3cc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ── ⚙  CONFIGURE: replace with your GitHub repo URL ──────────────────────────\n",
    "REPO_URL   = 'https://github.com/YOUR_USERNAME/OR-SIM.git'\n",
    "REPO_DIR   = '/kaggle/working/OR-SIM'\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "if not os.path.isdir(os.path.join(REPO_DIR, '.git')):\n",
    "    subprocess.run(['git', 'clone', '--depth', '1', REPO_URL, REPO_DIR], check=True)\n",
    "    print(f'Cloned → {REPO_DIR}')\n",
    "else:\n",
    "    subprocess.run(['git', '-C', REPO_DIR, 'pull', '--ff-only'], check=True)\n",
    "    print(f'Updated existing clone at {REPO_DIR}')\n",
    "\n",
    "# Install Python deps from the repo's requirements file\n",
    "req = os.path.join(REPO_DIR, 'requirements.txt')\n",
    "if os.path.exists(req):\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-r', req, '--quiet'], check=True)\n",
    "    print('Python dependencies installed.')\n",
    "else:\n",
    "    print('⚠  requirements.txt not found — install deps manually if needed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20306357",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 4 — Locate the MedGemma GGUF model\n",
    "\n",
    "The backend expects the GGUF at `<repo_root>/models/medgemma/medgemma-4b-it-Q3_K_M.gguf`.\n",
    "We create a symlink from your Kaggle dataset path to that location so nothing else changes.\n",
    "\n",
    "### Option A — Kaggle Dataset (recommended)\n",
    "1. Go to **kaggle.com → Datasets → New Dataset**\n",
    "2. Upload `medgemma-4b-it-Q3_K_M.gguf` (2.1 GB) as a private dataset\n",
    "   (name it e.g. `medgemma-4b-it-q3-k-m`)\n",
    "3. Attach it to this notebook via *+ Add data*\n",
    "4. The file will appear at `/kaggle/input/<dataset-slug>/medgemma-4b-it-Q3_K_M.gguf`\n",
    "\n",
    "### Option B — Already inside the repo\n",
    "Change `GGUF_DATASET_PATH` to point inside `REPO_DIR/models/medgemma/...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f091da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── ⚙  CONFIGURE: path where Kaggle mounted your dataset ─────────────────────\n",
    "GGUF_DATASET_PATH = '/kaggle/input/medgemma-4b-it-q3-k-m/medgemma-4b-it-Q3_K_M.gguf'\n",
    "# If the file is already inside the cloned repo (e.g. git-lfs), use:\n",
    "#   GGUF_DATASET_PATH = os.path.join(REPO_DIR, 'models/medgemma/medgemma-4b-it-Q3_K_M.gguf')\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "assert os.path.exists(GGUF_DATASET_PATH), (\n",
    "    f'GGUF not found at {GGUF_DATASET_PATH}\\n'\n",
    "    'Check the dataset path or attach/upload the model file (see cell instructions).'\n",
    ")\n",
    "print(f'✓  GGUF found: {GGUF_DATASET_PATH} ({os.path.getsize(GGUF_DATASET_PATH)/1e9:.2f} GB)')\n",
    "\n",
    "# Create symlink at the location the backend code expects\n",
    "GGUF_LINK = os.path.join(REPO_DIR, 'models', 'medgemma', 'medgemma-4b-it-Q3_K_M.gguf')\n",
    "os.makedirs(os.path.dirname(GGUF_LINK), exist_ok=True)\n",
    "\n",
    "if not os.path.exists(GGUF_LINK):\n",
    "    os.symlink(GGUF_DATASET_PATH, GGUF_LINK)\n",
    "    print(f'✓  Symlinked: {GGUF_LINK}')\n",
    "else:\n",
    "    print(f'✓  Symlink already exists: {GGUF_LINK}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc63f11d",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 5 — Verify MedASR ONNX model\n",
    "\n",
    "The `model.int8.onnx` and `tokens.txt` are committed to the repo under `models/medasr/`.\n",
    "This cell confirms they are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_dir = os.path.join(REPO_DIR, 'models', 'medasr')\n",
    "for fname in ('model.int8.onnx', 'tokens.txt'):\n",
    "    fpath = os.path.join(asr_dir, fname)\n",
    "    if os.path.exists(fpath):\n",
    "        print(f'✓  {fname}  ({os.path.getsize(fpath)/1e6:.1f} MB)')\n",
    "    else:\n",
    "        print(f'✗  MISSING: {fpath}')\n",
    "        print('   → make sure models/medasr/ is committed or add it to a Kaggle dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3faaf3",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 6 — Install pyngrok and configure your auth token\n",
    "\n",
    "1. Sign up (free) at https://ngrok.com\n",
    "2. Go to https://dashboard.ngrok.com/get-started/your-authtoken\n",
    "3. Copy your auth token and paste it below.\n",
    "\n",
    "> **Security:** treat your auth token like a password — do not commit this notebook with\n",
    "> the real token in it. Use a Kaggle Secret (Settings → Secrets) and call\n",
    "> `kaggle_secrets.UserSecretsClient().get_secret('NGROK_TOKEN')` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b62aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([sys.executable, '-m', 'pip', 'install', 'pyngrok', '--quiet'], check=True)\n",
    "print('pyngrok installed.')\n",
    "\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# ── ⚙  CONFIGURE: paste your ngrok auth token ────────────────────────────────\n",
    "# Recommended: use a Kaggle Secret instead of hard-coding\n",
    "#   from kaggle_secrets import UserSecretsClient\n",
    "#   NGROK_AUTH_TOKEN = UserSecretsClient().get_secret('NGROK_TOKEN')\n",
    "NGROK_AUTH_TOKEN = 'YOUR_NGROK_AUTH_TOKEN'\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "print('✓  ngrok auth token configured.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110edb57",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 7 — Start the FastAPI backend server\n",
    "\n",
    "The server is launched in a daemon thread so the notebook remains interactive.\n",
    "Startup takes ~10-20 s while MedGemma loads into GPU VRAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc19df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, threading, time\n",
    "import uvicorn\n",
    "\n",
    "# Make sure the repo's Python packages are importable\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "_server_started = threading.Event()\n",
    "\n",
    "def _run_server():\n",
    "    from backend.server.app import create_app\n",
    "    app = create_app()\n",
    "    # Signal ready before blocking in uvicorn.run\n",
    "    _server_started.set()\n",
    "    uvicorn.run(\n",
    "        app,\n",
    "        host='0.0.0.0',\n",
    "        port=8000,\n",
    "        log_level='info',\n",
    "        # Disable reload — we are inside a thread, not the main process\n",
    "        reload=False,\n",
    "    )\n",
    "\n",
    "server_thread = threading.Thread(target=_run_server, name='or-sim-server', daemon=True)\n",
    "server_thread.start()\n",
    "\n",
    "# Wait up to 30 s for uvicorn to bind the port\n",
    "print('Waiting for FastAPI server to start', end='', flush=True)\n",
    "deadline = time.time() + 30\n",
    "import socket\n",
    "while time.time() < deadline:\n",
    "    try:\n",
    "        with socket.create_connection(('127.0.0.1', 8000), timeout=1):\n",
    "            break\n",
    "    except OSError:\n",
    "        print('.', end='', flush=True)\n",
    "        time.sleep(1)\n",
    "\n",
    "print()\n",
    "\n",
    "# Quick health check\n",
    "import urllib.request, json as _json\n",
    "try:\n",
    "    with urllib.request.urlopen('http://127.0.0.1:8000/api/health', timeout=5) as r:\n",
    "        health = _json.loads(r.read())\n",
    "    print(f'✓  Server healthy: {health}')\n",
    "except Exception as e:\n",
    "    print(f'✗  Health check failed: {e}')\n",
    "    print('   → check the server thread output above for errors.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626f6232",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 8 — Open ngrok tunnel and print the public URLs\n",
    "\n",
    "**Copy the printed HTTPS URL — you will need it for the local frontend.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03faa9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close any stale tunnels from previous runs\n",
    "for t in ngrok.get_tunnels():\n",
    "    ngrok.disconnect(t.public_url)\n",
    "\n",
    "# Open a new HTTPS tunnel to port 8000\n",
    "tunnel = ngrok.connect(8000, bind_tls=True)\n",
    "NGROK_HTTPS = tunnel.public_url          # e.g. https://abcd-1234.ngrok-free.app\n",
    "NGROK_WSS   = NGROK_HTTPS.replace('https://', 'wss://')  # WebSocket URL\n",
    "\n",
    "print()\n",
    "print('=' * 65)\n",
    "print('  OR-SIM BACKEND IS LIVE')\n",
    "print('=' * 65)\n",
    "print(f'  HTTPS (REST API) : {NGROK_HTTPS}')\n",
    "print(f'  WSS  (WebSocket) : {NGROK_WSS}/ws/state')\n",
    "print('=' * 65)\n",
    "print()\n",
    "print('Next step → configure your LOCAL FRONTEND (see Cell 9).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3709654",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 9 — Connect the local frontend\n",
    "\n",
    "Run the following steps **on your local machine** (`d:\\OR-SIM\\frontend`):\n",
    "\n",
    "### Step 1 — Create `frontend/.env.local`\n",
    "\n",
    "```\n",
    "# d:\\OR-SIM\\frontend\\.env.local\n",
    "VITE_BACKEND_URL=https://abcd-1234.ngrok-free.app\n",
    "```\n",
    "\n",
    "Replace `https://abcd-1234.ngrok-free.app` with the **HTTPS URL printed in Cell 8**.\n",
    "\n",
    "### Step 2 — Start the Vite dev server\n",
    "\n",
    "Open a terminal and run:\n",
    "\n",
    "```powershell\n",
    "cd d:\\OR-SIM\\frontend\n",
    "npm run dev\n",
    "```\n",
    "\n",
    "Vite will output:\n",
    "\n",
    "```\n",
    "VITE v6.x.x  ready in 641 ms\n",
    "\n",
    "  ➜  Local:   http://localhost:5173/\n",
    "```\n",
    "\n",
    "### Step 3 — Open the simulator\n",
    "\n",
    "1. Open **http://localhost:5173** in Chrome / Edge.\n",
    "2. Pick a surgery (Heart Transplant / Liver Resection / Kidney PCNL).\n",
    "3. Click **▶ Start Session**.\n",
    "4. Allow microphone access when the browser asks.\n",
    "5. Speak surgical commands — machines will glow ON/OFF in the 3D room in real-time.\n",
    "\n",
    "### Stopping the session\n",
    "\n",
    "- Click **⏹ Stop Session** in the UI, then interrupt the Kaggle kernel to free GPU VRAM.\n",
    "- Delete the ngrok tunnel with `ngrok.disconnect(NGROK_HTTPS)` in a new cell if needed.\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "| Symptom | Fix |\n",
    "|---|---|\n",
    "| WS status dot stays red | Check `.env.local` — no trailing slash on the URL |\n",
    "| `ERR_NGROK_3200` | Free ngrok tier allows 1 tunnel; close any other open sessions |\n",
    "| `ModuleNotFoundError: backend` | Cell 7 sets `sys.path`; re-run Cell 7 |\n",
    "| GGUF not found | Verify dataset is attached to the notebook in Kaggle settings |\n",
    "| Kaggle kernel timeout | Kaggle sessions expire after ~12 h; re-run cells 7-8 to restart |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42133b82",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 10 — Live sanity check (optional)\n",
    "\n",
    "Confirms the tunnel is reachable from inside Kaggle and prints the full system state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4b19d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json as _json\n",
    "\n",
    "for path, label in [('/api/health', 'Health'), ('/api/state', 'State')]:\n",
    "    url = f'{NGROK_HTTPS}{path}'\n",
    "    try:\n",
    "        req = urllib.request.Request(url, headers={'ngrok-skip-browser-warning': '1'})\n",
    "        with urllib.request.urlopen(req, timeout=10) as r:\n",
    "            data = _json.loads(r.read())\n",
    "        print(f'✓  {label}: {_json.dumps(data, indent=2)[:400]}')\n",
    "    except Exception as e:\n",
    "        print(f'✗  {label} check failed: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572132d7",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 11 — Keep-alive ping (optional — run while you use the UI)\n",
    "\n",
    "Kaggle kills idle kernels after ~30 min. Run this cell to send a health-check ping\n",
    "every 60 seconds and keep the kernel alive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b111d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, urllib.request, datetime\n",
    "\n",
    "PING_INTERVAL = 60   # seconds\n",
    "MAX_PINGS     = 60   # 60 × 60 s = 1 hour; increase if needed\n",
    "\n",
    "print(f'Keep-alive started — pinging every {PING_INTERVAL}s (interrupt kernel to stop).')\n",
    "for i in range(1, MAX_PINGS + 1):\n",
    "    time.sleep(PING_INTERVAL)\n",
    "    try:\n",
    "        req = urllib.request.Request(\n",
    "            f'{NGROK_HTTPS}/api/health',\n",
    "            headers={'ngrok-skip-browser-warning': '1'},\n",
    "        )\n",
    "        with urllib.request.urlopen(req, timeout=5) as r:\n",
    "            status = r.status\n",
    "    except Exception:\n",
    "        status = 'error'\n",
    "    ts = datetime.datetime.now().strftime('%H:%M:%S')\n",
    "    print(f'  [{ts}] ping #{i:02d} → HTTP {status}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
